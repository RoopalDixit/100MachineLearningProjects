{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fxmfmvmtsm",
   "source": "## 7. Next Steps\n\nThis notebook demonstrated the core functionality of the BERT text summarization tool. Here's what you can do next:\n\n### Command Line Usage\n```bash\n# Run the CLI tool\npython cli.py extractive --text \"Your text...\" --num-sentences 3\n\n# Interactive mode\npython cli.py interactive\n```\n\n### Web Interface\n```bash\n# Start the web app\npython web_app.py\n# Open browser to http://localhost:5000\n```\n\n### Testing and Evaluation\n```bash\n# Run comprehensive tests\npython test_summarization.py\n```\n\n### Further Exploration\n- Try different BERT models (DistilBERT for speed, BERT-large for quality)\n- Experiment with abstractive summarization using the HybridSummarizer\n- Fine-tune on domain-specific data\n- Integrate with your own applications using the Python API\n\nHappy summarizing! ğŸ‰",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "n8h84ntb7i",
   "source": "# Advanced techniques and tips\n\nprint(\"ğŸ’¡ Performance Tips:\")\nprint(\"=\" * 30)\nprint(\"1. ğŸš€ First run may be slow due to model downloading\")\nprint(\"2. âš¡ Subsequent runs are much faster (models cached)\")\nprint(\"3. ğŸ“ Shorter texts process faster\")\nprint(\"4. ğŸ§  Consider DistilBERT for speed:\")\nprint(\"   summarizer = BERTExtractiveSummarizer('distilbert-base-uncased')\")\nprint(\"5. ğŸ–¥ï¸  GPU acceleration available if CUDA installed\")\n\nprint(f\"\\nğŸ”§ Customization Options:\")\nprint(\"=\" * 30)\nprint(\"â€¢ num_sentences: Control summary length\")\nprint(\"â€¢ max_sentence_length: Filter very long sentences\")\nprint(\"â€¢ preprocess: Clean HTML, URLs, etc.\")\nprint(\"â€¢ Different BERT models for different domains\")\n\nprint(f\"\\nğŸ“Š Quality Guidelines:\")\nprint(\"=\" * 30)\nprint(\"â€¢ Input should be >100 words for best results\")\nprint(\"â€¢ Use preprocessing for web content\")\nprint(\"â€¢ Adjust sentence count based on document length\")\nprint(\"â€¢ Compare ROUGE scores for evaluation\")\n\n# Example with custom parameters\nprint(f\"\\nğŸ¯ Custom Configuration Example:\")\nprint(\"-\" * 40)\n\ncustom_summary = summarizer.extractive_summarize(\n    sample_text,\n    num_sentences=4,\n    max_sentence_length=100  # Prefer shorter sentences\n)\n\nprint(f\"ğŸ“‹ Custom summary (4 sentences, max 100 words each):\")\nprint(custom_summary)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "fzkbei0l99u",
   "source": "## 6. Advanced Usage and Tips\n\nHere are some advanced techniques and optimization tips for better summarization results.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "bkefylkrz5f",
   "source": "# Load sample dataset\ndataset_loader = DatasetLoader()\nsample_data = dataset_loader.load_cnn_dailymail_sample()\n\nprint(f\"ğŸ“‚ Loaded {len(sample_data)} sample documents\")\n\n# Test each document\nfor i, data_point in enumerate(sample_data):\n    print(f\"\\nğŸ“„ Document {i+1}: {data_point['title']}\")\n    print(\"-\" * 50)\n    \n    document = data_point['document']\n    reference = data_point['summary']\n    \n    # Generate summary\n    start_time = time.time()\n    generated = summarizer.extractive_summarize(document, num_sentences=2)\n    processing_time = time.time() - start_time\n    \n    # Evaluate\n    evaluation = evaluator.evaluate_summary(document, reference, generated)\n    \n    print(f\"ğŸ“Š Processing time: {processing_time:.3f}s\")\n    print(f\"ğŸ“ Original: {len(document.split())} words\")\n    print(f\"ğŸ“ Generated: {len(generated.split())} words\")\n    print(f\"ğŸ“ˆ ROUGE-1 F1: {evaluation['rouge1_f1']:.4f}\")\n    print(f\"ğŸ“ˆ Compression: {evaluation['compression_ratio']:.3f}\")\n    print(f\"\\nğŸ“š Reference: {reference}\")\n    print(f\"ğŸ“‹ Generated: {generated}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "y625u9k8e2a",
   "source": "## 5. Testing with Real Data\n\nLet's test the summarizer with some sample datasets.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "dydtogdm3mi",
   "source": "# Initialize evaluator\nevaluator = SummarizationEvaluator()\n\n# Generate a summary to evaluate\ngenerated_summary = summarizer.extractive_summarize(sample_text, num_sentences=2)\n\n# Reference summary (what we consider a good summary)\nreference_summary = \"\"\"\nArtificial intelligence is intelligence demonstrated by machines that perceive their environment \nand take actions to maximize their goals. The AI field includes reasoning, learning, natural \nlanguage processing, and draws upon computer science, mathematics, psychology, and other fields.\n\"\"\"\n\nprint(\"ğŸ“‹ Generated Summary:\")\nprint(generated_summary)\nprint(f\"\\nğŸ“š Reference Summary:\")\nprint(reference_summary)\n\n# Calculate ROUGE scores\nscores = evaluator.calculate_rouge_scores(reference_summary, generated_summary)\n\nprint(f\"\\nğŸ“Š ROUGE Scores:\")\nfor metric, score in scores.items():\n    print(f\"  {metric}: {score:.4f}\")\n\n# Calculate compression ratio\ncompression_ratio = evaluator.calculate_compression_ratio(sample_text, generated_summary)\nprint(f\"\\nğŸ“ˆ Compression Ratio: {compression_ratio:.3f}\")\nprint(f\"ğŸ“ Original: {len(sample_text.split())} words â†’ Summary: {len(generated_summary.split())} words\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "91uk40zhlln",
   "source": "## 4. Evaluation and Metrics\n\nLet's evaluate the quality of our summaries using ROUGE scores and other metrics.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "gi83qqx2kka",
   "source": "# Initialize preprocessor and test with messy text\npreprocessor = TextPreprocessor()\n\nmessy_text = \"\"\"\n<p>This is a sample text with HTML tags.</p>\nVisit our website at https://example.com for more information!\nContact us at: info@example.com\n\nThis sentence has weird    spacing   and formatting.\nThis is way too short.\nThis is a proper sentence that should be kept in the final output after preprocessing and cleaning operations.\n\"\"\"\n\nprint(\"ğŸ§¹ Original messy text:\")\nprint(repr(messy_text))\n\ncleaned_text = preprocessor.preprocess_document(messy_text)\nprint(f\"\\nâœ¨ Cleaned text:\")\nprint(repr(cleaned_text))\n\n# Summarize the cleaned text\nif len(cleaned_text.split()) > 10:\n    clean_summary = summarizer.extractive_summarize(cleaned_text, num_sentences=1)\n    print(f\"\\nğŸ“‹ Summary of cleaned text:\")\n    print(clean_summary)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "omtfbg2gv3",
   "source": "## 3. Text Preprocessing\n\nThe tool includes text preprocessing capabilities to clean and normalize input text.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "i8758hafue",
   "source": "# Generate summaries with different lengths\nfor num_sentences in [1, 2, 3]:\n    print(f\"\\nğŸ” {num_sentences}-sentence summary:\")\n    print(\"-\" * 40)\n    \n    start_time = time.time()\n    summary = summarizer.extractive_summarize(sample_text, num_sentences=num_sentences)\n    processing_time = time.time() - start_time\n    \n    print(f\"â±ï¸  Processing time: {processing_time:.3f}s\")\n    print(f\"ğŸ“ Summary length: {len(summary.split())} words\")\n    print(f\"ğŸ“‹ Summary: {summary}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "zs9yn2teb8",
   "source": "## 2. Basic Summarization\n\nLet's generate a summary with different lengths to see how the tool works.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "fot4sixnyzp",
   "source": "# Sample text for demonstration\nsample_text = \"\"\"\nArtificial intelligence (AI) is intelligence demonstrated by machines, in contrast to the natural\nintelligence displayed by humans and animals. Leading AI textbooks define the field as the study\nof \"intelligent agents\": any device that perceives its environment and takes actions that maximize\nits chance of successfully achieving its goals. Colloquially, the term \"artificial intelligence\"\nis often used to describe machines that mimic \"cognitive\" functions that humans associate with the\nhuman mind, such as \"learning\" and \"problem solving\". As machines become increasingly capable,\ntasks considered to require \"intelligence\" are often removed from the definition of AI, a phenomenon\nknown as the AI effect. A quip in Tesler's Theorem says \"AI is whatever hasn't been done yet.\"\nFor instance, optical character recognition is frequently excluded from things considered to be AI,\nhaving become a routine technology. Modern machine learning techniques are heavy on data and require\nlarge amounts of computing power. The traditional problems of AI research include reasoning, knowledge\nrepresentation, planning, learning, natural language processing, perception, and the ability to move\nand manipulate objects. General intelligence is among the field's long-term goals. Approaches include\nstatistical methods, computational intelligence, and traditional symbolic AI. Many tools are used in\nAI, including versions of search and mathematical optimization, artificial neural networks, and methods\nbased on statistics, probability and economics. The AI field draws upon computer science, information\nengineering, mathematics, psychology, linguistics, philosophy, and many other fields.\n\"\"\"\n\nprint(\"ğŸ“„ Sample text loaded:\")\nprint(f\"ğŸ“Š Length: {len(sample_text.split())} words\")\nprint(f\"ğŸ“ Preview: {sample_text[:200]}...\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "rbukyxp9pw",
   "source": "# Initialize the BERT extractive summarizer\nprint(\"ğŸ”„ Initializing BERT summarizer...\")\nsummarizer = BERTExtractiveSummarizer()\n\nprint(\"âœ… Summarizer initialized!\")\nprint(f\"ğŸ“‹ Using model: {summarizer.model_name}\")\nprint(f\"ğŸ–¥ï¸  Device: {summarizer.device}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "1qo8rvxr9cv",
   "source": "## 1. Basic Setup and Initialization\n\nLet's start by initializing the BERT summarizer and preparing some sample text.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "ew6jnwqxj3u",
   "source": "# Import required libraries\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom text_summarizer import BERTExtractiveSummarizer, HybridSummarizer\nfrom utils import TextPreprocessor, SummarizationEvaluator, DatasetLoader\nimport time",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "1mjhwgkre1c",
   "source": "# BERT Text Summarization Tool ğŸ¤–\n\nThis notebook demonstrates how to use BERT for extractive text summarization. The tool uses BERT embeddings to identify and extract the most important sentences from a document.\n\n## Features\n- ğŸ” **Extractive Summarization**: Uses BERT to identify key sentences\n- ğŸ§  **Semantic Understanding**: Leverages BERT's contextual embeddings  \n- âš™ï¸ **Customizable**: Adjustable summary length and preprocessing\n- ğŸ“Š **Evaluation**: ROUGE scores and compression metrics",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}